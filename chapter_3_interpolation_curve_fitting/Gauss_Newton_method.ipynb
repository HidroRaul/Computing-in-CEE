{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Curve fitting - Gauss-Newton Method for nonlinear regression\n",
    "\n",
    "by Xiaofeng Liu, Ph.D., P.E.\n",
    "Associate Professor\n",
    "\n",
    "Department of Civil and Environmental Engineering\n",
    "\n",
    "Institute of CyberScience\n",
    "\n",
    "Penn State University \n",
    "\n",
    "223B Sackett Building, University Park, PA 16802\n",
    "\n",
    "Web: http://water.engr.psu.edu/liu/\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least-squares regression\n",
    "\n",
    "Let's assume the given set of data is denoted as $(x_i, y_i)$, $i\\in(0,N-1)$. Here the total number of data points is $N$. Note that here the index starts at 0 to be consistent with the zero-based index in Python. In lecture notes and the book, the index starts at 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear regression\n",
    "\n",
    "Up until now, we only considered linear regressions, polynomial regressions, and linearizable nonlinear regressions. For general nonlinear regression, the basic idea is the same, i.e., to determine the coefficients for the minimization of the sum of the squares of the residuals. Unlike linear regression, an iterative approach has to be used to calculate the coefficients. One such method is the Gauss-Newton method. \n",
    "\n",
    "Let the sought nonlinear regressional function be $f(x)$ and the data points can be written as\n",
    "\\begin{equation}\n",
    "y_i = f(x_i; a_0,a_1, \\ldots , a_m) + e_i\n",
    "\\end{equation}\n",
    "where $a_0,a_1, \\ldots , a_m$ are the $m+1$ parameters in the nonlinear function which need to be determined through least-squares regression. $e_i$ is the error for data point $i$. In vector form, the fitting parameters can be written as\n",
    "\\begin{equation}\n",
    "\\mathbf{A} = \n",
    "\\begin{bmatrix}\n",
    "           a_0\\\\\n",
    "           a_1\\\\\n",
    "           \\vdots \\\\\n",
    "           a_{N-1} \n",
    "         \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{E} = \n",
    "\\begin{bmatrix}\n",
    "           e_0\\\\\n",
    "           e_1\\\\\n",
    "           \\vdots \\\\\n",
    "           e_{N-1} \n",
    "         \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The derivation of the Gauss-Newton method is as follows. For convience, the case of two paramters $a_0$ and $a_1$, i.e., $m$ = 1, is considred. The conclusion can be easily extended to general case. The nonlinear function can expanded around the paramter values using Taylor series as\n",
    "\\begin{equation}\n",
    "f(x_i; a_0, a_1)_{s+1} = f(x_i; a_0, a_1)_{s} + \\frac{\\partial f(x_i; a_0, a_1)_{s}}{\\partial a_0} \\Delta a_0 + \\frac{\\partial f(x_i; a_0, a_1)_{s}}{\\partial a_1} \\Delta a_1 + ...\n",
    "\\end{equation}\n",
    "Higher order terms can be omitted. Here, $s$ is the iteration number. The goal of the Gauss-Newton method is to perform iterations to improve the estimates of parameters $a_0$ and $a_1$. Note that from iteration $s$ to iteration $s+1$, the parameters have been changed, thus $f(x_i; a_0, a_1)_{s+1}$ and $f(x_i; a_0, a_1)_{s}$ have different values. That is the essence of the Taylor series expansion above. \n",
    "\n",
    "The changes of $a_0$ and $a_1$ between iterations can be written as\n",
    "\\begin{equation}\n",
    "\\Delta a_0 = a_{0,s+1}-a_{0,s}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\Delta a_1 = a_{1,s+1}-a_{1,s}\n",
    "\\end{equation}\n",
    "\n",
    "Plus the Taylor series expansion into the error equation above, one can get\n",
    "\\begin{equation}\n",
    "y_i - f(x_i; a_0, a_1)_{s} = \\frac{\\partial f(x_i; a_0, a_1)_{s}}{\\partial a_0} \\Delta a_0 + \\frac{\\partial f(x_i; a_0, a_1)_{s}}{\\partial a_1} \\Delta a_1 + e_i\n",
    "\\end{equation}\n",
    "for all data points $i$ = 0, 1, 2, ..., N-1. This equation can be compactly written in matrix form as\n",
    "\\begin{equation}\n",
    "\\mathbf{D} = \\mathbf{J}_s \\Delta \\mathbf{A} + \\mathbf{E}\n",
    "\\end{equation}\n",
    "where vector $\\mathbf{D}$ is made of the difference between the data point values and the predicted function values (at current iteration) as\n",
    "\\begin{equation}\n",
    "\\mathbf{D} = \n",
    "\\begin{bmatrix}\n",
    "           y_0 - f(x_0)_s \\\\\n",
    "           y_1 - f(x_1)_s \\\\\n",
    "           \\vdots \\\\\n",
    "           y_{N-1} - f(x_{N-1})_s \n",
    "         \\end{bmatrix}\n",
    "\\end{equation}\n",
    "The matrix $\\mathbf{J}$ is the so-called Jacobian matrix which is made of the function $f(x)$'s partial derivatives with respect to the parameters $a_0$ and $a_1$. The matrix $\\mathbf{J}$ has a dimension of $N \\times 2$ because we have $N$ data points and 2 parameters. \n",
    "\\begin{equation}\n",
    "\\mathbf{J}_s = \n",
    "   \\begin{bmatrix}\n",
    "           \\partial f(x_0; a_0, a_1)_{s}/\\partial a_0  & \\partial f(x_0; a_0, a_1)_{s}/\\partial a_1\\\\\n",
    "           \\partial f(x_1; a_0, a_1)_{s}/\\partial a_0  & \\partial f(x_1; a_0, a_1)_{s}/\\partial a_1\\\\\n",
    "           \\vdots \\\\\n",
    "           \\partial f(x_{N-1}; a_0, a_1)_{s}/\\partial a_0  & \\partial f(x_{N-1}; a_0, a_1)_{s}\\partial a_1\n",
    "   \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "The vector $\\Delta \\mathbf{A}$ has a length of 2 (because we have 2 parameters) and is defined as\n",
    "\\begin{equation}\n",
    "\\Delta \\mathbf{A} = \n",
    "   \\begin{bmatrix}\n",
    "           \\Delta a_0 \\\\\n",
    "           \\Delta a_1 \n",
    "   \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "This vector equation can be treated as a linear regression with data points $(\\mathbf{J}, \\mathbf{D})$ and $\\Delta \\mathbf{A}$ is the linear regression parameter vector. \\mathbf{E} is the error. Using the same least-squares regression to this problem, one can write the nomal equation (in vector form of course) as\n",
    "\\begin{equation}\n",
    "\\left( \\mathbf{J}_s^T \\mathbf{J}_s \\right) \\Delta \\mathbf{A} = \\mathbf{J}_s^T   \\mathbf{D}\n",
    "\\end{equation}\n",
    "This is a $2 \\times 2$ linear equation system. It can be solved for $\\Delta \\mathbf{A}$ as\n",
    "\\begin{equation}\n",
    "\\Delta \\mathbf{A} = \\left( \\mathbf{J}_s^T \\mathbf{J}_s \\right)^{-1} \\mathbf{J}_s^T   \\mathbf{D}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The following example fits a Monod-type equation (or saturation-growth-rate equation) with a given set of data points:\n",
    "\\begin{equation}\n",
    "y = a_0 \\frac{x}{a_1 + x}\n",
    "\\end{equation}\n",
    "Here, $y$ is the specific growth rate of microorganisms, $a_0$ is the maximum specific growth rate, $x$ is the concentration of the limiting nutrient, $a_1$ is the half-saturation constant, i.e., the value of $x$ when the growth rate is half of the maximum. \n",
    "\n",
    "The residual is for each data points is\n",
    "\\begin{equation}\n",
    "e_i = y_i - a_0 \\frac{x_i}{a_1 + x_i}\n",
    "\\end{equation}\n",
    "Then the Jacobian $J$, which is $e_i$ taking derivatieve with respect to $a_j$, $j$=0 or 1.\n",
    "\\begin{equation}\n",
    "\\frac{\\partial e_i}{\\partial a_0} = -\\frac{x_i}{a_1+x_i}\n",
    "\\end{equation}\n",
    "and \n",
    "\\begin{equation}\n",
    "\\frac{\\partial e_i}{\\partial a_1} = \\frac{a_0 x_i}{\\left(a_1+x_i\\right)^2}\n",
    "\\end{equation}\n",
    "\n",
    "The Gauss-Newton method iteration to update the paramters $a_j$ is then\n",
    "\\begin{equation}\n",
    "\\mathbf{A}^{s+1} = \\mathbf{A}^{s+1} + \\left(\\mathbf{J}^T \\mathbf{J} \\right)^{-1} \\mathbf{J}^T \\mathbf{e}\\left(\\mathbf{A}^{s+1} \\right)\n",
    "\\end{equation}\n",
    "where $s$ is the iteration number and $s$ = 0, 1, 2, $\\ldots$. \n",
    "\n",
    "As in any iterative schemes, there should be a stopping criterion $\\epsilon$. For example, one criterion can be the relative error between two successive iterations:\n",
    "\\begin{equation}\n",
    "\\left| \\frac{a_j^{s+1}-a_j^{s}}{a_j^{s+1}}  \\right| < \\epsilon\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial guess for the two parameters: \n",
      " [[0.2]\n",
      " [1. ]]\n",
      "iter =  0\n",
      "(abs((A[0]-A_old[0])/A[0]) =  [0.56025567]\n",
      "(abs((A[1]-A_old[1])/A[1]) =  [0.4593264]\n",
      "iter =  1\n",
      "(abs((A[0]-A_old[0])/A[0]) =  [0.00394693]\n",
      "(abs((A[1]-A_old[1])/A[1]) =  [0.30831006]\n",
      "iter =  2\n",
      "(abs((A[0]-A_old[0])/A[0]) =  [0.00198786]\n",
      "(abs((A[1]-A_old[1])/A[1]) =  [0.03050907]\n",
      "iter =  3\n",
      "(abs((A[0]-A_old[0])/A[0]) =  [0.00013531]\n",
      "(abs((A[1]-A_old[1])/A[1]) =  [0.00109377]\n",
      "iter =  4\n",
      "(abs((A[0]-A_old[0])/A[0]) =  [3.28763122e-06]\n",
      "(abs((A[1]-A_old[1])/A[1]) =  [2.35887229e-05]\n",
      "iter =  5\n",
      "(abs((A[0]-A_old[0])/A[0]) =  [6.97212526e-08]\n",
      "(abs((A[1]-A_old[1])/A[1]) =  [4.98374892e-07]\n",
      "Final results for the two parameters: \n",
      " [[0.45758489]\n",
      " [1.45980935]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('text', usetex=True)  #allow the use of Latex for math expressions and equations\n",
    "plt.rc('font', family='serif') #specify the default font family to be \"serif\"\n",
    "\n",
    "#data points\n",
    "x=np.array([0.07, 1.04,2.06, 3.06, 4.09, 5.01, 6.05, 7.05, 8.02, 9.03, 10.03, 11.07,12.01,13.02,14.08, 15.01, 16.01, 17.04, 18.01, 19.03, 20.05])\n",
    "y=np.array([0.03, 0.21, 0.24, 0.31, 0.32, 0.40, 0.35, 0.33, 0.41, 0.43, 0.38, 0.41, 0.43, 0.42, 0.42, 0.38, 0.46, 0.43, 0.41, 0.38, 0.44])\n",
    "\n",
    "#max iterations\n",
    "max_iter = 200\n",
    "\n",
    "#convergence criterion for the fitting parameters\n",
    "eps = 1E-6\n",
    "\n",
    "rows = len(x) #number of data points\n",
    "cols = 2      #two parameters a0 and a1\n",
    "\n",
    "A = np.array([[.2],[1.0]]) # original guess for A\n",
    "print(\"Initial guess for the two parameters: \\n\",A)\n",
    "\n",
    "J = np.zeros((rows,cols)) # Jacobian matrix from r\n",
    "r = np.zeros((rows,1)) #r equations\n",
    "\n",
    "# component of the Jacobian matrix: df_da0\n",
    "def df_da0(A1,xi):\n",
    "    return -(xi/(A1+xi))\n",
    "\n",
    "# component of the Jacobian matrix: df_da1\n",
    "def df_da1(A0,A1,xi):\n",
    "    return ((A0*xi)/((A1+xi)**2))\n",
    "\n",
    "#calculate the residual e for a given data points with current parameters\n",
    "def residual(x,y,A0,A1):\n",
    "    return (y - ((A0*x)/(A1+x)))\n",
    "\n",
    "#the Gauss-Newton method iteration\n",
    "iter = 0\n",
    "while iter <= max_iter:\n",
    "    print(\"iter = \", iter)\n",
    "    A_old = A        #save the parameter values from previous iteration\n",
    "        \n",
    "    #calculate Jacobian matrix J and residual vector e for current iteration.\n",
    "    for j in range(rows):                      #loop over all data points\n",
    "        r[j,0] = residual(x[j],y[j],A[0],A[1]) #\n",
    "        J[j,0] = df_da0(A[1],x[j])\n",
    "        J[j,1] = df_da1(A[0],A[1],x[j])\n",
    "\n",
    "    Jt =  J.T    #get the transpose of J\n",
    "    A = A - np.dot(np.dot(np.linalg.inv(np.dot(Jt,J)),Jt),r)\n",
    "    \n",
    "    #convergence check\n",
    "    print(\"(abs((A[0]-A_old[0])/A[0]) = \", (abs((A[0]-A_old[0])/A[0])))\n",
    "    print(\"(abs((A[1]-A_old[1])/A[1]) = \", (abs((A[1]-A_old[1])/A[1])))\n",
    "    \n",
    "    if((abs((A[0]-A_old[0])/A[0])<eps) or (abs((A[1]-A_old[1])/A[1])<eps)):\n",
    "        break\n",
    "\n",
    "    iter += 1\n",
    "\n",
    "print(\"Final results for the two parameters: \\n\", A)    \n",
    "    \n",
    "#plot the data and fitted curve\n",
    "# plotting the original data points\n",
    "plt.scatter(x, y, c = \"r\", marker = \"x\", s = 40, label='original data') \n",
    "\n",
    "# predicted value using the fitting curve\n",
    "x_pred = np.linspace(0,20,50)\n",
    "y_pred = A[0][0]*x_pred/(A[1][0]+x_pred) \n",
    "np.reshape(y_pred, (1,50))\n",
    "\n",
    "# plotting the regression line \n",
    "plt.plot(x_pred, y_pred, color = \"k\", label='fitted line') \n",
    "\n",
    "plt.xlabel('x',fontsize=16) \n",
    "plt.ylabel('y',fontsize=16) \n",
    "\n",
    "plt.ylim([0, 0.6])\n",
    "\n",
    "#show the ticks on both axes and set the font size \n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.legend(loc='upper left',fontsize=14,frameon=False)\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, the following code uses the \"curve_fit\" function in [SciPy (Scientific Python)](https://www.scipy.org)'s optimize library, which uses non-linear least squares to fit a function for a give set of data. You can compare the resulted values of $a_0$ and $a_1$ with those from above. They should match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a0, a1 =  0.4575848670975289 1.4598088795953368\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "plt.rc('text', usetex=True)  #allow the use of Latex for math expressions and equations\n",
    "plt.rc('font', family='serif') #specify the default font family to be \"serif\"\n",
    "\n",
    "#data points\n",
    "x=np.array([0.07, 1.04,2.06, 3.06, 4.09, 5.01, 6.05, 7.05, 8.02, 9.03, 10.03, 11.07,12.01,13.02,14.08, 15.01, 16.01, 17.04, 18.01, 19.03, 20.05])\n",
    "y=np.array([0.03, 0.21, 0.24, 0.31, 0.32, 0.40, 0.35, 0.33, 0.41, 0.43, 0.38, 0.41, 0.43, 0.42, 0.42, 0.38, 0.46, 0.43, 0.41, 0.38, 0.44])\n",
    "\n",
    "#define the fitting function\n",
    "def f(x, a0, a1):\n",
    "    return a0*x/(a1+x)\n",
    "\n",
    "fitting_parameters, covariance = curve_fit(f, x, y)\n",
    "a0, a1 = fitting_parameters\n",
    "\n",
    "print(\"a0, a1 = \", a0, a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
